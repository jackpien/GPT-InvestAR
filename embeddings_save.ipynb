{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to set up this notebook\n",
    "\n",
    "```\n",
    "python3 -m venv venv_embeddings_save\n",
    "pip install -r requirements_embeddings_save.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import (\n",
    "    GPTVectorStoreIndex, StorageContext, ServiceContext, LangchainEmbedding)\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import chromadb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from embeddings_save import (\n",
    "    save_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = None\n",
    "config_file = f\"/app/config.json\"\n",
    "with open(config_file) as json_file:\n",
    "    config_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 512\n",
    "CHUNK_OVERLAP = 32\n",
    "TRAIN_CUTOFF_YEAR = 2017\n",
    "NUM_SAMPLES_TRAIN = 10 # 1000\n",
    "NUM_SAMPLES_TEST = 5 # 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the targets df generated from make_targets.py\n",
    "df_targets = pd.read_pickle(config_dict['targets_df_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets_train = \\\n",
    "    df_targets.loc[lambda x: x.era <= TRAIN_CUTOFF_YEAR].reset_index(drop=True)\n",
    "df_targets_test = \\\n",
    "    df_targets.loc[lambda x: x.era > TRAIN_CUTOFF_YEAR].reset_index(drop=True)\n",
    "df_targets_train_sampled = \\\n",
    "    df_targets_train.sample(n=NUM_SAMPLES_TRAIN).reset_index(drop=True)\n",
    "df_targets_test_sampled = \\\n",
    "    df_targets_test.sample(n=NUM_SAMPLES_TEST).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_dfs(df_targets_train_sampled, df_targets_test_sampled, config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/app/venv_embeddings_save/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = LangchainEmbedding(\n",
    "        HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_index_02(embeddings_path, embedding_model, \n",
    "                  symbol, ar_date, config_dict):\n",
    "    db = chromadb.PersistentClient(\n",
    "        path=os.path.join(embeddings_path, symbol, ar_date))\n",
    "    chroma_collection = db.create_collection(\"ar_date\")\n",
    "    \n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    service_context = ServiceContext.from_defaults(\n",
    "        llm=None,\n",
    "        embed_model=embedding_model,\n",
    "        chunk_size = CHUNK_SIZE, \n",
    "        chunk_overlap=CHUNK_OVERLAP)\n",
    "    \n",
    "    ar_filing_path = os.path.join(\n",
    "        config_dict['annual_reports_pdf_save_directory'], symbol)\n",
    "    ar_fn = f\"{ar_filing_path}/{ar_date}.pdf\"\n",
    "    documents = SimpleDirectoryReader(input_files=[ar_fn]).load_data()\n",
    "    \n",
    "    _ = VectorStoreIndex.from_documents(\n",
    "        documents, storage_context=storage_context, \n",
    "        service_context=service_context\n",
    "    )\n",
    "\n",
    "def save_embeddings_02(df, embedding_model, save_directory, config_dict):\n",
    "    for i in df.index:\n",
    "        start_time = time.time()\n",
    "        curr_series = df.loc[i]\n",
    "        symbol = curr_series['symbol']\n",
    "        ar_date = curr_series['report_date'].date().strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "        save_path = os.path.join(save_directory, symbol, ar_date)\n",
    "        if os.path.exists(save_path):\n",
    "            # Don't need to save twice\n",
    "            continue\n",
    "\n",
    "        save_index_02(\n",
    "            save_directory, embedding_model,  symbol, ar_date, config_dict)\n",
    "\n",
    "        print(\"Completed: {}, {}, {} in {:.2f}s\".format(i+1, symbol, ar_date, time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 1, INTC, 2002-12-28 in 354.38s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 2, INTC, 2003-12-27 in 259.87s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 3, NVDA, 2005-01-30 in 195.48s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 4, NVDA, 2007-01-28 in 232.52s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 5, NVDA, 2006-01-29 in 204.14s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 6, NVDA, 2002-01-27 in 137.89s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 7, INTC, 2007-12-29 in 226.25s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 8, NVDA, 2003-01-26 in 149.01s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 9, INTC, 2004-12-25 in 202.72s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 10, INTC, 2013-12-28 in 311.22s\n"
     ]
    }
   ],
   "source": [
    "save_embeddings_02(\n",
    "    df_targets_train_sampled, embedding_model, \n",
    "    config_dict['embeddings_for_training_directory'], config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 1, NVDA, 2018-01-28 in 180.82s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 2, INTC, 2021-12-25 in 236.55s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 3, NVDA, 2019-01-27 in 172.84s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 4, NVDA, 2020-01-26 in 186.80s\n",
      "LLM is explicitly disabled. Using MockLLM.\n",
      "Completed: 5, INTC, 2020-12-26 in 328.49s\n"
     ]
    }
   ],
   "source": [
    "save_embeddings_02(\n",
    "    df_targets_test_sampled, embedding_model, \n",
    "    config_dict['embeddings_for_testing_directory'], config_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_embeddings_save",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
