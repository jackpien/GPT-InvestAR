{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to set up this notebook\n",
    "\n",
    "```\n",
    "python3 -m venv venv_make_targets\n",
    "pip install -r requirements_openbb.txt\n",
    "pip install -r requirements_make_targets.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import argparse\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from openbb_terminal.sdk import openbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_targets import (\n",
    "    get_all_targets, get_normalized_column, bin_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = None\n",
    "config_file = f\"/app/config.json\"\n",
    "with open(config_file) as json_file:\n",
    "    config_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_targets_02(symbol, start_date, end_date, price_data_sp500, all_10k_df):\n",
    "    '''\n",
    "    Function to generate target return information for each symbol based on \n",
    "    annual report dates\n",
    "    Args:\n",
    "        symbol: stock ticker\n",
    "        start_date: overall historical start date from where price data is to be fetched\n",
    "        end_date: overall end date upto which price data is to be fetched\n",
    "        price_data_sp500: Prefetched dataframe for ticker ^GSPC which gives price data for S&P500\n",
    "    Returns:\n",
    "        Pandas DF containing percentage returns between annual report dates for the symbol\n",
    "    '''\n",
    "    price_data = openbb.stocks.load(\n",
    "        symbol, start_date=start_date, end_date=end_date, verbose=False)\n",
    "    ar_dates_series = all_10k_df[all_10k_df[\"ticker\"] == symbol][\"reportDate\"]\n",
    "    ar_dates = list(ar_dates_series.sort_values(ascending=True))\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(len(ar_dates)-1):\n",
    "        curr_report_date = datetime.strptime(ar_dates[i], '%Y-%m-%d')\n",
    "\n",
    "        #Start and end dates are offset by 2 days to be conservative and allowing the price to settle.\n",
    "        curr_start_date = \\\n",
    "            datetime.strptime(ar_dates[i], '%Y-%m-%d') + timedelta(days=2)\n",
    "        curr_end_date_12m = \\\n",
    "            datetime.strptime(ar_dates[i+1], '%Y-%m-%d') - timedelta(days=2)\n",
    "        num_days_12m = (curr_end_date_12m - curr_start_date).days\n",
    "        if (num_days_12m < 200):\n",
    "            continue\n",
    "\n",
    "        target_dict = get_all_targets(\n",
    "            price_data, curr_start_date, num_days_12m, 'target')\n",
    "        sp500_dict = get_all_targets(\n",
    "            price_data_sp500, curr_start_date, num_days_12m, 'sp500')\n",
    "        target_dict.update(sp500_dict)\n",
    "        target_df = pd.DataFrame.from_dict(target_dict, orient='index').T\n",
    "        target_df['report_date'] = curr_report_date\n",
    "        target_df['start_date'] = curr_start_date\n",
    "        target_df['end_date'] = curr_end_date_12m\n",
    "        df = pd.concat([df, target_df], ignore_index=True)\n",
    "    df['symbol'] = symbol\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_targets_all_symbols_02(start_date, end_date, all_10k_df):\n",
    "    '''\n",
    "    Function to return the complete dataframe for all symbols and all annual report date periods\n",
    "    '''\n",
    "    symbol_names = all_10k_df[\"ticker\"].unique()\n",
    "    price_data_sp500 = openbb.stocks.load(\n",
    "        '^GSPC', start_date=start_date, end_date=end_date, \n",
    "        verbose=False)\n",
    "    full_df = pd.DataFrame()\n",
    "\n",
    "    for i, symbol in enumerate(symbol_names):\n",
    "        df = make_targets_02(\n",
    "            symbol, start_date, end_date, price_data_sp500, all_10k_df)\n",
    "        full_df = pd.concat([full_df, df], ignore_index=True)\n",
    "        print('Completed: {}/{}'.format(i+1, len(symbol_names)))\n",
    "    return full_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe of tickers we care about\n",
    "all_10k_df = None\n",
    "with open(config_dict[\"10k_df_pkl_pathfn\"], \"rb\") as f:\n",
    "    all_10k_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_10k_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openbb.__version__\n",
    "start_date='2002-01-01'\n",
    "end_date='2023-12-31'\n",
    "\n",
    "# JPIEN\n",
    "# Targets is really \"return %\" for the given period\n",
    "# target_min is the min return (0.2 quantile) for the given start / end period\n",
    "# target_max is the max return (0.98 quantile)\n",
    "# target_Xn is the return of adj close price at the 3m, 6m, end date compared\n",
    "#   with the start_date adj close price\n",
    "targets_df = make_targets_all_symbols_02(start_date, end_date, all_10k_df)\n",
    "targets_df_filtered = targets_df.loc[lambda x: ~(x.isnull().any(axis=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Era is \"year\" of annual report filing\n",
    "targets_df_filtered['era'] = targets_df_filtered['report_date'].apply(\n",
    "    lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop duplicates if they exist. Could be if consecutive annual reports are published in same year.\n",
    "targets_df_filtered_dropdup = targets_df_filtered.drop_duplicates(\n",
    "    subset=['era', 'symbol']).reset_index(drop=True)\n",
    "\n",
    "# Drop eras where there is only one ticker\n",
    "def remove_single_entries(df):\n",
    "    if len(df) > 1:\n",
    "        return df\n",
    "    \n",
    "targets_df_filtered_dedup = targets_df_filtered_dropdup.groupby(\n",
    "    'era', group_keys=False).apply(lambda df: remove_single_entries(df)\n",
    ")\n",
    "\n",
    "# Get name of target columns - \n",
    "#   target_min, target_max, target_3m, target_6m, target_9m, target_12m\n",
    "target_cols = [\n",
    "    c for c in targets_df_filtered_dedup.columns if c.startswith('target')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate normalised target columns\n",
    "# JPIEN\n",
    "# For each annual report year, determine where each ticker's \n",
    "#   return falls on a gaussian curve in relation to each other.\n",
    "for target in target_cols:\n",
    "    targets_df_filtered_dedup = targets_df_filtered_dedup.groupby(\n",
    "        'era', group_keys=False).apply(\n",
    "            lambda df: get_normalized_column(df, target)\n",
    "            )\n",
    "    \n",
    "# Not used?!\n",
    "target_cols_normalised = [\n",
    "    c for c in targets_df_filtered_dedup.columns if \\\n",
    "        ( c.startswith('target') & (c.endswith('normalised')) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create final target column for Machine Learning model building\n",
    "input_col_target = 'target_12m_normalised'\n",
    "output_col_target = 'target_ml'\n",
    "\n",
    "# JPIEN\n",
    "# bin_targets uses qcut to bin the target_12m_norm values in\n",
    "#   relationship to each other - 0->0.2, 0.2->0.4, etc - so\n",
    "#   5 bins total for 6 quantiles.\n",
    "targets_df_filtered_dedup = targets_df_filtered_dedup.groupby(\n",
    "    'era', group_keys=False).apply(\n",
    "        lambda df: bin_targets(\n",
    "            df, input_col_target, output_col_target, \n",
    "            [0, 0.2, 0.4, 0.6, 0.8, 1.0], \n",
    "            ['0.0', '0.25', '0.5', '0.75', '1.0'])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_dict['targets_df_path'], 'wb') as handle:\n",
    "    pickle.dump(\n",
    "        targets_df_filtered_dedup, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_make_targets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
